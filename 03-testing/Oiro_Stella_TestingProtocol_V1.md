# Testing Protocol - Get a Room UX/UI Project
**Project:** Get a Room Online Booking System  
**Designer:** Stella Oiro  
**Testing Phases:** Mid-Fidelity and High-Fidelity Prototype Testing  
**Timeline:** Week 1 (Mid-Fi) and Week 2 (Hi-Fi)

## Testing Overview

### Objectives
1. **Validate user flows** for daily, weekly, and monthly booking processes
2. **Test usability** of interactive wireframes with real Kisumu users
3. **Identify pain points** in current booking experience and proposed solutions
4. **Verify cultural appropriateness** of payment methods and language choices
5. **Assess mobile usability** given Kenya's mobile-first market
6. **Gather insights** for high-fidelity design improvements

### Testing Approach
- **Method:** Moderated usability testing with task-based scenarios
- **Format:** In-person sessions at Get a Room or nearby locations
- **Duration:** 45-60 minutes per session
- **Participants:** 5 users per testing phase (10 total)
- **Tools:** Wireframe prototypes, mobile devices, observation notes

---

## Phase 1: Mid-Fidelity Testing (Week 1)

### Participant Recruitment
**Target: 5 participants representing core user groups**

#### Participant Profile Requirements:
1. **Current coworking space users** (3 participants)
   - Currently use Get a Room or similar spaces
   - Mix of daily and weekly users
   - Age range: 25-45

2. **Potential new users** (2 participants)
   - Have heard of coworking but haven't tried
   - Work from home/cafes currently
   - Age range: 22-40

#### Recruitment Criteria:
- **Location:** Based in Kisumu or frequent visitors
- **Tech comfort:** Comfortable using smartphones for basic tasks
- **Payment methods:** Use M-Pesa regularly
- **Language:** Comfortable in English (can assist in Kiswahili if needed)
- **Availability:** Can commit to 1-hour session

#### Recruitment Strategy:
- Contact Grace Akinyi for current customer referrals
- Post in local business WhatsApp groups
- Visit university campuses (Maseno, Jaramogi Oginga Odinga)
- Check with other coworking spaces in Kisumu
- Offer compensation: KES 1,000 shopping voucher

### Testing Setup

#### Location Options:
1. **Primary:** Get a Room coworking space (familiar environment)
2. **Secondary:** Quiet cafe with good WiFi
3. **Backup:** University meeting room

#### Equipment Needed:
- Laptop with wireframe prototypes loaded
- Smartphone/tablet for mobile testing
- Audio recorder (with permission)
- Notebook for observations
- Consent forms
- Compensation vouchers
- Backup internet connection

#### Session Structure (60 minutes):
1. **Welcome & Setup** (10 minutes)
2. **Background Questions** (10 minutes)
3. **Task Testing** (30 minutes)
4. **Debrief Discussion** (10 minutes)

### Testing Scenarios

#### Scenario 1: Daily Hot Spot Booking (15 minutes)
**Context:** "You're a freelance graphic designer who needs workspace for today. You've heard about Get a Room and want to book a spot for this afternoon."

**Tasks:**
1. Navigate to daily booking page
2. Select appropriate workspace type
3. Choose time slot for today, 2 PM - 6 PM
4. Add contact information
5. Select M-Pesa payment option
6. Complete booking process

**Success Criteria:**
- Completes booking without assistance
- Understands pricing structure
- Comfortable with M-Pesa payment flow
- Can find confirmation information

**Observations to Note:**
- Time taken for each step
- Any confusion about workspace types
- Hesitation around payment method
- Mobile vs desktop preference

#### Scenario 2: Weekly Team Booking (15 minutes)
**Context:** "You lead a small startup team and need workspace for your team of 3 people for next week, Monday through Friday."

**Tasks:**
1. Navigate to weekly booking section
2. Select appropriate week dates
3. Choose team workspace option
4. Add team member details
5. Review pricing and discounts
6. Submit booking request

**Success Criteria:**
- Understands team booking process
- Can navigate calendar selection
- Recognizes pricing benefits
- Completes form with team information

**Observations to Note:**
- Understanding of calendar interface
- Reaction to team pricing
- Ability to input multiple team members
- Preference for approval vs instant booking

### Mid-Fidelity Testing Questions

#### Pre-Test Questions (Background)
1. **Current Work Habits**
   - Where do you currently work? (home, office, cafe, coworking)
   - How often do you need workspace outside your usual location?
   - What challenges do you face with your current setup?

2. **Technology Usage**
   - How comfortable are you booking things online?
   - What payment methods do you prefer? (M-Pesa, bank, cash)
   - Do you use smartphone or computer more for business tasks?

3. **Coworking Experience**
   - Have you used coworking spaces before?
   - How do you currently find and book workspace?
   - What information is important when choosing workspace?

#### Post-Task Questions (After each scenario)
1. **Ease of Use**
   - How easy was it to find what you needed?
   - What was confusing or unclear?
   - Did anything surprise you?

2. **Trust and Confidence**
   - How confident do you feel about this booking?
   - Would you trust this payment process?
   - What would make you more confident?

3. **Mobile Experience**
   - Did you prefer mobile or desktop view?
   - Was the text readable on mobile?
   - Were buttons easy to tap?

#### Final Debrief Questions
1. **Overall Impression**
   - What did you like most about the booking process?
   - What frustrated you the most?
   - How does this compare to other booking experiences?

2. **Feature Priorities**
   - Which features are most important to you?
   - What's missing that you would want?
   - Would you use this system to book workspace?

3. **Cultural Fit**
   - Does this feel appropriate for Kisumu business culture?
   - Are the payment options right for you?
   - Would you want Kiswahili language option?

### Data Collection & Analysis

#### Quantitative Metrics:
- **Task completion rate** (successful booking completion)
- **Time to complete** each scenario
- **Error rate** (wrong clicks, form mistakes)
- **Mobile vs desktop preference**

#### Qualitative Insights:
- **Pain points** in user flow
- **Mental models** around booking workspace
- **Trust factors** for online payment
- **Language and cultural preferences**

#### Analysis Framework:
1. **Usability Issues:** Critical, moderate, minor
2. **User Preferences:** Strong, moderate, neutral
3. **Technical Problems:** Blocking, hindering, cosmetic
4. **Cultural Considerations:** Essential, important, nice-to-have

---

## Phase 2: High-Fidelity Testing (Week 2)

### Advanced Prototype Testing

#### Updated Participant Mix (5 new participants):
1. **Grace Akinyi** (client validation)
2. **Returning customer** from Get a Room
3. **New potential customer** (different from Phase 1)
4. **Team leader** who books for others
5. **Visiting professional** to Kisumu

#### Enhanced Scenarios:

##### Scenario 3: Monthly Membership Application
**Context:** "You're establishing a consulting business in Kisumu and need permanent workspace. You want to explore monthly membership options."

**Tasks:**
1. Compare membership tiers
2. Select workspace location and type
3. Choose contract duration
4. Set up recurring M-Pesa payments
5. Complete membership application

##### Scenario 4: Admin Dashboard (Grace only)
**Context:** "It's Monday morning and you need to check today's bookings, handle a payment issue, and create a quick booking for a walk-in customer."

**Tasks:**
1. Review today's occupancy status
2. Identify overdue payments
3. Create quick booking for new customer
4. Send payment reminder SMS

### High-Fidelity Testing Focus Areas:

#### Visual Design Validation:
- Color scheme appropriateness
- Typography readability
- Cultural sensitivity of imagery
- Brand perception and trust

#### Interaction Design:
- Micro-interactions and feedback
- Loading states and error handling
- Form validation and help text
- Mobile gesture compatibility

#### Technical Integration:
- M-Pesa payment flow simulation
- SMS confirmation process
- Calendar synchronization
- Real-time availability updates

### Advanced Testing Questions

#### Design-Specific Questions:
1. **Visual Appeal**
   - Does this look professional and trustworthy?
   - Are the colors and images appropriate?
   - Is the information well-organized?

2. **Interaction Quality**
   - Do the buttons and links behave as expected?
   - Is feedback clear when you complete actions?
   - Do error messages help you fix problems?

3. **Mobile Optimization**
   - Is everything easy to reach with your thumb?
   - Can you read everything without zooming?
   - Do forms work well on mobile?

#### Business Model Validation:
1. **Pricing Perception**
   - Are the prices reasonable for the value offered?
   - Do the discounts motivate longer bookings?
   - Would you pay the membership fees?

2. **Service Appeal**
   - What would make you choose Get a Room over competitors?
   - Which services are most valuable to you?
   - What additional services would you want?

### Testing Environment Setup

#### Realistic Testing Conditions:
- **Internet speed:** Test with slower 3G connections
- **Device variety:** Android phones (common in Kenya)
- **Lighting conditions:** Outdoor visibility testing
- **Interruption scenarios:** Phone calls during booking

#### A/B Testing Elements:
- Payment method order (M-Pesa first vs card first)
- Language toggle placement
- Booking confirmation style
- Error message tone (formal vs friendly)

---

## Testing Documentation

### Session Recording Template

#### Participant Information:
- **ID:** T1_001 (Phase_ParticipantNumber)
- **Demographics:** Age, gender, profession, location
- **Tech profile:** Smartphone model, internet usage
- **Coworking experience:** Current usage, previous booking methods

#### Task Performance:
- **Scenario:** [Scenario name and description]
- **Start time:** [Timestamp]
- **Completion status:** Success/Failure/Partial
- **End time:** [Timestamp]
- **Errors/Confusion:** [Detailed notes]
- **User quotes:** [Exact words when possible]

#### Behavioral Observations:
- **Navigation patterns:** How they move through the interface
- **Decision points:** Where they pause or hesitate
- **Emotional reactions:** Frustration, delight, confusion
- **Help-seeking:** When they look for assistance

### Synthesis Process

#### After Each Session:
1. **Immediate notes:** Capture key insights while fresh
2. **Quote documentation:** Record exact user feedback
3. **Issue categorization:** Sort by type and severity
4. **Pattern identification:** Note recurring themes

#### After Each Phase:
1. **Cross-participant analysis:** Compare experiences
2. **Priority ranking:** Order issues by impact
3. **Solution brainstorming:** Generate design improvements
4. **Prototype updates:** Implement critical fixes

---

## Success Metrics & KPIs

### Phase 1 (Mid-Fi) Success Criteria:
- **85%+ task completion rate** across all scenarios
- **Average booking time under 5 minutes** for daily bookings
- **High confidence scores** (4/5+) for payment security
- **Strong mobile preference** (60%+ prefer mobile)
- **No critical usability blockers** identified

### Phase 2 (Hi-Fi) Success Criteria:
- **90%+ task completion rate** with improved prototype
- **Positive brand perception** (professional, trustworthy)
- **Client approval** from Grace Akinyi
- **Clear feature priorities** for development phase
- **Validated business model** (pricing acceptance)

### Risk Mitigation:

#### If Low Task Completion (<70%):
- Conduct immediate guerrilla testing sessions
- Simplify user flows based on identified blockers
- Test alternative interaction patterns

#### If Poor Mobile Experience:
- Prioritize mobile-first redesign
- Test with smaller screen sizes
- Optimize touch targets and text size

#### If Payment Method Concerns:
- Research local payment preferences more deeply
- Test alternative payment flows
- Consider cash payment integration

#### If Cultural Misalignment:
- Conduct additional cultural research
- Test with older user demographics
- Consider Kiswahili language integration

---

## Deliverables from Testing

### Phase 1 Report:
1. **Executive Summary** of findings
2. **Task completion analysis** with metrics
3. **Priority issues list** with severity ratings
4. **User quotes compilation** organized by theme
5. **Recommendations** for prototype improvements

### Phase 2 Report:
1. **Design validation results** with visual examples
2. **Feature prioritization** based on user feedback
3. **Technical requirements** identified during testing
4. **Business model validation** summary
5. **Final recommendations** for development phase

### Testing Artifacts:
1. **Video recordings** (with consent) of key sessions
2. **Annotated screenshots** showing user confusion points
3. **User journey maps** based on observed behavior
4. **Persona updates** with real user insights
5. **Prototype iteration documentation**

---

## Post-Testing Actions

### Immediate (Same Day):
- Document critical issues requiring immediate fixes
- Update prototype with obvious improvements
- Schedule follow-up sessions if needed

### Short-term (Within 3 Days):
- Complete detailed analysis and reporting
- Present findings to Grace Akinyi
- Plan high-fidelity design improvements

### Medium-term (Within 1 Week):
- Implement approved design changes
- Prepare materials for development handoff
- Schedule validation session with Grace

### Long-term (Ongoing):
- Monitor user feedback post-launch
- Plan iterative improvements
- Document lessons learned for future projects

---

**Testing Conducted by:** Stella Oiro  
**Contact for Questions:** stella.oiro@example.com  
**Emergency Contact:** +254 XXX XXX XXX

**Note:** All testing will be conducted with proper consent and participant confidentiality. Testing materials and recordings will be used solely for this project and deleted after completion unless participants explicitly consent to other uses.